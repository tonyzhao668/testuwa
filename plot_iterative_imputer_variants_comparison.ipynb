{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Imputing missing values with variants of IterativeImputer\n",
    "\n",
    ".. currentmodule:: sklearn\n",
    "\n",
    "The :class:`~impute.IterativeImputer` class is very flexible - it can be\n",
    "used with a variety of estimators to do round-robin regression, treating every\n",
    "variable as an output in turn.\n",
    "\n",
    "In this example we compare some estimators for the purpose of missing feature\n",
    "imputation with :class:`~impute.IterativeImputer`:\n",
    "\n",
    "* :class:`~linear_model.BayesianRidge`: regularized linear regression\n",
    "* :class:`~tree.DecisionTreeRegressor`: non-linear regression\n",
    "* :class:`~ensemble.ExtraTreesRegressor`: similar to missForest in R\n",
    "* :class:`~neighbors.KNeighborsRegressor`: comparable to other KNN\n",
    "  imputation approaches\n",
    "\n",
    "Of particular interest is the ability of\n",
    ":class:`~impute.IterativeImputer` to mimic the behavior of missForest, a\n",
    "popular imputation package for R. In this example, we have chosen to use\n",
    ":class:`~ensemble.ExtraTreesRegressor` instead of\n",
    ":class:`~ensemble.RandomForestRegressor` (as in missForest) due to its\n",
    "increased speed.\n",
    "\n",
    "Note that :class:`~neighbors.KNeighborsRegressor` is different from KNN\n",
    "imputation, which learns from samples with missing values by using a distance\n",
    "metric that accounts for missing values, rather than imputing them.\n",
    "\n",
    "The goal is to compare different estimators to see which one is best for the\n",
    ":class:`~impute.IterativeImputer` when using a\n",
    ":class:`~linear_model.BayesianRidge` estimator on the California housing\n",
    "dataset with a single value randomly removed from each row.\n",
    "\n",
    "For this particular pattern of missing values we see that\n",
    ":class:`~ensemble.ExtraTreesRegressor` and\n",
    ":class:`~linear_model.BayesianRidge` give the best results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# To use this experimental feature, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "X_full, y_full = fetch_california_housing(return_X_y=True)\n",
    "# ~2k samples is enough for the purpose of the example.\n",
    "# Remove the following two lines for a slower run with different error bars.\n",
    "X_full = X_full[::10]\n",
    "y_full = y_full[::10]\n",
    "n_samples, n_features = X_full.shape\n",
    "\n",
    "# Estimate the score on the entire dataset, with no missing values\n",
    "br_estimator = BayesianRidge()\n",
    "score_full_data = pd.DataFrame(\n",
    "    cross_val_score(\n",
    "        br_estimator, X_full, y_full, scoring='neg_mean_squared_error',\n",
    "        cv=N_SPLITS\n",
    "    ),\n",
    "    columns=['Full Data']\n",
    ")\n",
    "\n",
    "# Add a single missing value to each row\n",
    "X_missing = X_full.copy()\n",
    "y_missing = y_full\n",
    "missing_samples = np.arange(n_samples)\n",
    "missing_features = rng.choice(n_features, n_samples, replace=True)\n",
    "X_missing[missing_samples, missing_features] = np.nan\n",
    "\n",
    "# Estimate the score after imputation (mean and median strategies)\n",
    "score_simple_imputer = pd.DataFrame()\n",
    "for strategy in ('mean', 'median'):\n",
    "    estimator = make_pipeline(\n",
    "        SimpleImputer(missing_values=np.nan, strategy=strategy),\n",
    "        br_estimator\n",
    "    )\n",
    "    score_simple_imputer[strategy] = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring='neg_mean_squared_error',\n",
    "        cv=N_SPLITS\n",
    "    )\n",
    "\n",
    "# Estimate the score after iterative imputation of the missing values\n",
    "# with different estimators\n",
    "estimators = [\n",
    "    BayesianRidge(),\n",
    "    DecisionTreeRegressor(max_features='sqrt', random_state=0),\n",
    "    ExtraTreesRegressor(n_estimators=10, random_state=0),\n",
    "    KNeighborsRegressor(n_neighbors=15)\n",
    "]\n",
    "score_iterative_imputer = pd.DataFrame()\n",
    "for impute_estimator in estimators:\n",
    "    estimator = make_pipeline(\n",
    "        IterativeImputer(random_state=0, estimator=impute_estimator),\n",
    "        br_estimator\n",
    "    )\n",
    "    score_iterative_imputer[impute_estimator.__class__.__name__] = \\\n",
    "        cross_val_score(\n",
    "            estimator, X_missing, y_missing, scoring='neg_mean_squared_error',\n",
    "            cv=N_SPLITS\n",
    "        )\n",
    "\n",
    "scores = pd.concat(\n",
    "    [score_full_data, score_simple_imputer, score_iterative_imputer],\n",
    "    keys=['Original', 'SimpleImputer', 'IterativeImputer'], axis=1\n",
    ")\n",
    "\n",
    "# plot california housing results\n",
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "means = -scores.mean()\n",
    "errors = scores.std()\n",
    "means.plot.barh(xerr=errors, ax=ax)\n",
    "ax.set_title('California Housing Regression with Different Imputation Methods')\n",
    "ax.set_xlabel('MSE (smaller is better)')\n",
    "ax.set_yticks(np.arange(means.shape[0]))\n",
    "ax.set_yticklabels([\" w/ \".join(label) for label in means.index.tolist()])\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
